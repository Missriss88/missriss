import gradio as gr
import cv2
import fire_detector
import person_detector
import google.generativeai as genai
import numpy as np
import tempfile
from PIL import Image
import os

# ëª¨ë¸ ë¡œë”© (ê¸°ì¡´ê³¼ ë™ì¼, ìºì‹± ëŒ€ì‹  ì•± ì‹œì‘ ì‹œ ë¡œë“œ)
def load_models():
    """AI ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        fire_model = fire_detector.load_fire_model('fire2.pt')
        person_model = person_detector.load_person_model('yolov8n.pt')
        return fire_model, person_model
    except Exception as e:
        return None, None, f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

fire_model, person_model, load_error = load_models()
if fire_model is None or person_model is None:
    raise ValueError(load_error)

# ê³µí†µ í•¨ìˆ˜: í”„ë ˆì„ ë¶„ì„ ë° ì‹œê°í™” (ê¸°ì¡´ê³¼ ë™ì¼)
def analyze_and_draw_on_frame(frame, proximity_threshold):
    """í”„ë ˆì„ ë‚´ì—ì„œ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ìœ„í—˜ìƒí™©ì„ ë¶„ì„í•˜ì—¬ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    fire_boxes = fire_detector.detect_fire(frame, fire_model)
    person_boxes = person_detector.detect_person(frame, person_model)
    is_warning = False

    if fire_boxes:
        for f_box in fire_boxes:
            cv2.rectangle(frame, (f_box[0], f_box[1]), (f_box[2], f_box[3]), (0, 0, 255), 3)
            cv2.putText(frame, 'Fire', (f_box[0], f_box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
            for p_box in person_boxes:
                fire_center_x = f_box[0] + (f_box[2] - f_box[0]) / 2
                person_center_x = p_box[0] + (p_box[2] - p_box[0]) / 2
                if abs(fire_center_x - person_center_x) < proximity_threshold:
                    is_warning = True
                    cv2.rectangle(frame, (p_box[0], p_box[1]), (p_box[2], p_box[3]), (0, 165, 255), 4)
                else:
                    cv2.rectangle(frame, (p_box[0], p_box[1]), (p_box[2], p_box[3]), (255, 0, 0), 2)
                cv2.putText(frame, 'Person', (p_box[0], p_box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
    else:
        for p_box in person_boxes:
            cv2.rectangle(frame, (p_box[0], p_box[1]), (p_box[2], p_box[3]), (255, 0, 0), 2)
            cv2.putText(frame, 'Person', (p_box[0], p_box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)

    if is_warning:
        cv2.putText(frame, "WARNING: Person Near Fire!", (50, 60), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 255), 3)
        
    return frame, len(fire_boxes), len(person_boxes), is_warning

# ê³µí†µ í•¨ìˆ˜: AI ë¦¬í¬íŠ¸ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
def generate_report(fire_count, person_count, is_warning, image_frame, api_key):
    """íƒì§€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ Gemini AI ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not api_key:
        return "Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    try:
        genai.configure(api_key=api_key)
        pil_image = Image.fromarray(cv2.cvtColor(image_frame, cv2.COLOR_BGR2RGB))

        # ì‚¬ìš©ìë‹˜ì´ ì„ í˜¸í•˜ì…¨ë˜ ìƒì„¸ í”„ë¡¬í”„íŠ¸
        prompt_parts = [
            pil_image,
            "ë‹¹ì‹ ì€ CCTV ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” AI ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
            "\n## ì§€ì‹œì‚¬í•­",
            "ì²¨ë¶€ëœ ì´ë¯¸ì§€ì™€ ì•„ë˜ ìš”ì•½ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì•ˆì „ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.",
            "\n## ë¶„ì„ ë°ì´í„°",
            f"- í™”ì¬ ê°ì²´ ìˆ˜: {fire_count}",
            f"- ì‚¬ëŒ ê°ì²´ ìˆ˜: {person_count}",
            f"- ìœ„í—˜ ê²½ê³  (ì‚¬ëŒ-í™”ì¬ ê·¼ì ‘): {'ë°œìƒ' if is_warning else 'ì—†ìŒ'}",
            "\n## ë¶„ì„ ê°€ì´ë“œë¼ì¸",
            "1. **[ìƒí™© ë§¥ë½ íŒŒì•…]** ì´ë¯¸ì§€ ì† ë¶ˆì´ í†µì œëœ ìƒí™©(ì˜ˆ: ë“œëŸ¼í†µ ì•ˆì˜ ëª¨ë‹¥ë¶ˆ, ìº í”„íŒŒì´ì–´)ì¸ì§€, í†µì œë˜ì§€ ì•Šì€ ìœ„í—˜í•œ í™”ì¬(ì˜ˆ: ê±´ë¬¼ í™”ì¬, ì‚°ë¶ˆ)ì¸ì§€ ë¨¼ì € íŒë‹¨í•˜ì„¸ìš”. ì£¼ë³€ í™˜ê²½ê³¼ ì‚¬ëŒë“¤ì˜ í–‰ë™ì„ ê·¼ê±°ë¡œ ì œì‹œí•˜ì„¸ìš”.",
            "2. **[ìœ„í—˜ë„ í‰ê°€]** ìœ„ ë§¥ë½ì— ë”°ë¼ ìœ„í—˜ë„ë¥¼ 'ì•ˆì „', 'ì£¼ì˜', 'ê²½ê³ ', 'ì‹¬ê°' 4ë‹¨ê³„ë¡œ í‰ê°€í•˜ê³ , ê·¸ ì´ìœ ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.",
            "3. **[ê¶Œì¥ ì¡°ì¹˜]** í‰ê°€ëœ ìœ„í—˜ë„ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì¡°ì¹˜ë¥¼ 1~2ê°€ì§€ ì œì•ˆí•˜ì„¸ìš”. 'ê²½ê³ ' ë˜ëŠ” 'ì‹¬ê°' ë‹¨ê³„ì¼ ê²½ìš°, êµ¬ì²´ì ì¸ ëŒ€í”¼ ìš”ë ¹ì„ ë°˜ë“œì‹œ í¬í•¨ì‹œí‚¤ì„¸ìš”.",
            "\nìœ„ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
        ]
        
        model = genai.GenerativeModel('gemini-2.5-flash') 
        response = model.generate_content(prompt_parts)
        return response.text
    except Exception as e:
        return f"AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# ì›¹ìº  ì²˜ë¦¬ í•¨ìˆ˜
def webcam_analysis(img, proximity_threshold, api_key, generate_report_flag):
    if img is None:
        return None, "ì›¹ìº  ì´ë¯¸ì§€ë¥¼ ìº¡ì²˜í•´ì£¼ì„¸ìš”.", ""
    
    frame = np.array(img)
    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
    annotated_frame, f_count, p_count, is_warning = analyze_and_draw_on_frame(frame, proximity_threshold)
    result_img = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
    
    summary = f"ğŸ”¥ íƒì§€ëœ í™”ì¬: {f_count} ê±´\nğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ íƒì§€ëœ ì¸ì›: {p_count} ëª…\n{'ğŸš¨ ìœ„í—˜ ìƒí™© ë°œìƒ!' if is_warning else 'âœ… ìœ„í—˜ ìƒí™© ì—†ìŒ.'}"
    
    report = ""
    if generate_report_flag and is_warning:
        report = generate_report(f_count, p_count, is_warning, annotated_frame, api_key)
    
    return result_img, summary, report

# íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ í•¨ìˆ˜ (ì´ë¯¸ì§€)
def image_upload_analysis(uploaded_file, api_key, generate_report_flag):
    if uploaded_file is None:
        return None, "ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", ""
    
    image = Image.open(uploaded_file)
    frame = np.array(image)
    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
    annotated_frame, f_count, p_count, is_warning = analyze_and_draw_on_frame(frame, 150)
    result_img = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
    
    summary = f"ğŸ”¥ íƒì§€ëœ í™”ì¬: {f_count} ê±´\nğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ íƒì§€ëœ ì¸ì›: {p_count} ëª…\n{'ğŸš¨ ìœ„í—˜ ìƒí™© ë°œìƒ!' if is_warning else 'âœ… ìœ„í—˜ ìƒí™© ì—†ìŒ.'}"
    
    report = ""
    if generate_report_flag:
        report = generate_report(f_count, p_count, is_warning, annotated_frame, api_key)
    
    return result_img, summary, report

# íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ í•¨ìˆ˜ (ë¹„ë””ì˜¤)
def video_upload_analysis(uploaded_file, api_key, generate_report_flag):
    if uploaded_file is None:
        return None, "ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", ""
    
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    video_capture = cv2.VideoCapture(tfile.name)
    
    max_fire, max_person, is_any_warning = 0, 0, False
    last_warn_frame = None
    last_frame = None
    
    while video_capture.isOpened():
        success, frame = video_capture.read()
        if not success:
            break
        
        annotated_frame, f_count, p_count, warn = analyze_and_draw_on_frame(frame, 150)
        last_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
        
        max_fire = max(max_fire, f_count)
        max_person = max(max_person, p_count)
        if warn:
            is_any_warning = True
            last_warn_frame = annotated_frame.copy()
    
    video_capture.release()
    os.unlink(tfile.name)
    
    summary = f"ğŸ”¥ ìµœëŒ€ í™”ì¬ ìˆ˜: {max_fire} ê±´\nğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ìµœëŒ€ ì¸ì› ìˆ˜: {max_person} ëª…\n{'ğŸš¨ ìœ„í—˜ ìƒí™© ë°œìƒ!' if is_any_warning else 'âœ… ìœ„í—˜ ìƒí™© ì—†ìŒ.'}"
    
    report = ""
    if generate_report_flag:
        report_frame = last_warn_frame if last_warn_frame is not None else last_frame
        report = generate_report(max_fire, max_person, is_any_warning, report_frame, api_key)
    
    return last_frame, summary, report  # ë§ˆì§€ë§‰ í”„ë ˆì„ ë°˜í™˜ (ì „ì²´ ë¹„ë””ì˜¤ ì¶œë ¥ì€ ë³„ë„ ê³ ë ¤ í•„ìš”)

# Gradio ì¸í„°í˜ì´ìŠ¤
with gr.Blocks(title="AI í™”ì¬ ë° ì¸ëª… ì•ˆì „ ì‹œìŠ¤í…œ") as demo:
    gr.Markdown("# ğŸš¨ AI í™”ì¬ ë° ì¸ëª… ê°ì§€ ì‹œìŠ¤í…œ")
    gr.Markdown("ì´ë¯¸ì§€/ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì‹¤ì‹œê°„ ì›¹ìº ì„ í†µí•´ í™”ì¬ ë° ì¸ëª… ìœ„í—˜ì„ ê°ì§€í•˜ê³  AI ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    
    api_key = gr.Textbox(label="Google Gemini API í‚¤ ì…ë ¥", type="password", placeholder="API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    with gr.Tabs():
        with gr.Tab("ì‹¤ì‹œê°„ ì›¹ìº  ê°ì§€"):
            webcam_input = gr.Image(source="webcam", label="ì›¹ìº  ì…ë ¥ (ì‹¤ì‹œê°„ ìº¡ì²˜)")
            proximity_threshold = gr.Slider(minimum=50, maximum=500, value=150, label="ìœ„í—˜ ê·¼ì ‘ ê±°ë¦¬ ì„¤ì • (px)")
            generate_report_checkbox = gr.Checkbox(label="ìœ„í—˜ ì‹œ AI ë¦¬í¬íŠ¸ ìƒì„±")
            output_image = gr.Image(label="ë¶„ì„ëœ ì´ë¯¸ì§€")
            summary_text = gr.Textbox(label="ë¶„ì„ ê²°ê³¼")
            report_text = gr.Textbox(label="AI ë¦¬í¬íŠ¸")
            
            webcam_input.change(
                fn=webcam_analysis,
                inputs=[webcam_input, proximity_threshold, api_key, generate_report_checkbox],
                outputs=[output_image, summary_text, report_text]
            )
        
        with gr.Tab("íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„"):
            file_upload = gr.File(label="ì´ë¯¸ì§€ ë˜ëŠ” ë™ì˜ìƒ ì—…ë¡œë“œ (jpg, png, mp4 ë“±)")
            generate_report_checkbox_upload = gr.Checkbox(label="AI ë¦¬í¬íŠ¸ ìƒì„±")
            output_image_upload = gr.Image(label="ë¶„ì„ëœ ì´ë¯¸ì§€/ë§ˆì§€ë§‰ í”„ë ˆì„")
            summary_text_upload = gr.Textbox(label="ë¶„ì„ ê²°ê³¼")
            report_text_upload = gr.Textbox(label="AI ë¦¬í¬íŠ¸")
            
            def process_upload(file, api_key, generate_flag):
                if file.name.lower().endswith(('.jpg', '.jpeg', '.png')):
                    return image_upload_analysis(file, api_key, generate_flag)
                elif file.name.lower().endswith(('.mp4', '.mov', '.avi')):
                    return video_upload_analysis(file, api_key, generate_flag)
                else:
                    return None, "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.", ""
            
            file_upload.change(
                fn=process_upload,
                inputs=[file_upload, api_key, generate_report_checkbox_upload],
                outputs=[output_image_upload, summary_text_upload, report_text_upload]
            )

demo.launch()
