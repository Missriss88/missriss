# app1.py â€” Streamlit Cloud ì¢…í•©ë³¸
# - ëª¨ë“œ: ì›¹ìº  / ì´ë¯¸ì§€ ì—…ë¡œë“œ / ë™ì˜ìƒ ì—…ë¡œë“œ
# - ë¦¬í¬íŠ¸: ê·œì¹™ ê¸°ë°˜(ê¸°ë³¸) + GOOGLE_API_KEY ìˆìœ¼ë©´ Geminië¡œ ìš”ì•½
# - webrtcëŠ” video_frame_callback ë°©ì‹(ì•ˆì •), ë²„ì „ í˜¸í™˜ ì…”ì„ í¬í•¨

import os, math
from typing import Tuple, List
import google.generativeai as genai
import cv2
import av
import numpy as np
import streamlit as st

# ===== Streamlit<->webrtc êµ¬ë²„ì „ í˜¸í™˜ ì…”ì„ (experimental_rerun í˜¸ì¶œ ëŒ€ë¹„) =====
if not hasattr(st, "experimental_rerun") and hasattr(st, "rerun"):
    st.experimental_rerun = st.rerun  # webrtc ë‚´ë¶€ê°€ experimental_rerunì„ ë¶€ë¥´ë©´ rerunì„ ëŒ€ë¦¬ ì‹¤í–‰

from streamlit_webrtc import webrtc_streamer, WebRtcMode

# ===== í”„ë¡œì íŠ¸ íƒì§€ ëª¨ë“ˆ =====
import fire_detector       # load_fire_model(path), detect_fire(frame, model)
import person_detector     # load_person_model(path), detect_person(frame, model)

st.set_page_config(page_title="ì‹¤ì‹œê°„ í™”ì¬/ì¸ëª… ê°ì§€", page_icon="ğŸ”¥", layout="wide")

# -------------------------------------------------------
# (í•„ìš” ì‹œ ìˆ˜ì •) ëª¨ë¸ ê²½ë¡œ / ê¸°ë³¸ íŒŒë¼ë¯¸í„°
# -------------------------------------------------------
FIRE_PT   = os.path.abspath("fire2.pt")      # ì˜ˆ: ./fire2.pt
PERSON_PT = os.path.abspath("yolov8n.pt")    # ì˜ˆ: ./yolov8n.pt (YOLOv5ë©´ yolov5s.pt)
PROXIMITY_PX_DEFAULT = 150                   # í™”ì¬-ì‚¬ëŒ ì¤‘ì‹¬ê±°ë¦¬ ê²½ê³  ì„ê³„(px)

# -------------------------------------------------------
# ìœ í‹¸
# -------------------------------------------------------
def center_distance(a, b) -> float:
    ax = (a[0]+a[2])/2.0; ay = (a[1]+a[3])/2.0
    bx = (b[0]+b[2])/2.0; by = (b[1]+b[3])/2.0
    return math.hypot(ax-bx, ay-by)

def draw_boxes(frame_bgr, fire_boxes, person_boxes, warning: bool):
    out = frame_bgr.copy()
    # Fire
    for (x1,y1,x2,y2) in fire_boxes:
        cv2.rectangle(out,(x1,y1),(x2,y2),(0,0,255),2)
        cv2.putText(out,"FIRE",(x1,max(0,y1-6)),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)
    # Person
    for (x1,y1,x2,y2) in person_boxes:
        cv2.rectangle(out,(x1,y1),(x2,y2),(0,200,0),2)
        cv2.putText(out,"PERSON",(x1,max(0,y1-6)),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,200,0),2)
    # Warning banner
    if warning:
        h,w = out.shape[:2]
        cv2.rectangle(out,(0,0),(w,36),(0,0,255),-1)
        cv2.putText(out,"WARNING: PERSON NEAR FIRE",(10,26),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)
    return out

# -------------------------------------------------------
# ë¦¬í¬íŠ¸(ê·œì¹™ ê¸°ë°˜ + LLM í´ë°±)
# -------------------------------------------------------
def rule_based_report(fire_count:int, person_count:int, warning:bool)->str:
    if fire_count==0 and person_count==0:
        risk="ì•ˆì „"; summary="í™”ì¬ì™€ ì‚¬ëŒ ëª¨ë‘ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."; action="ë³„ë„ ì¡°ì¹˜ í•„ìš” ì—†ìŠµë‹ˆë‹¤."
    elif fire_count>0 and person_count==0:
        risk="ì£¼ì˜"; summary="ì‘ì€ ë¶ˆì´ íƒì§€ë˜ì—ˆì§€ë§Œ ì£¼ë³€ì— ì‚¬ëŒì€ ì—†ìŠµë‹ˆë‹¤."; action="ìƒí™©ì„ ê´€ì°°í•˜ì„¸ìš”. í™•ì‚°/ì—°ê¸° ì¦ê°€ ì‹œ ì§„í™” ì¡°ì¹˜ë¥¼ ê³ ë ¤í•˜ì„¸ìš”."
    elif fire_count>0 and person_count>0 and not warning:
        risk="ì£¼ì˜"; summary="ë¶ˆì´ ìˆìœ¼ë‚˜ ì‚¬ëŒì€ ì•ˆì „ê±°ë¦¬ì—ì„œ ê´€ì°° ì¤‘ì…ë‹ˆë‹¤."; action="ì•ˆì „ê±°ë¦¬ë¥¼ ìœ ì§€í•˜ê³  ì†Œí™”ê¸° ë“± ëŒ€ë¹„ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."
    else:
        risk="ê²½ê³ "; summary="ë¶ˆ ê·¼ì²˜ì—ì„œ ì‚¬ëŒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."; action="ì¦‰ì‹œ ì•ˆì „ê±°ë¦¬ë¥¼ í™•ë³´í•˜ê³  í•„ìš” ì‹œ ì†Œí™”/ëŒ€í”¼ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”."
    return f"""[ìƒí™© ìš”ì•½]
- í™”ì¬: {fire_count}ê±´ / ì¸ì›: {person_count}ëª… / ê·¼ì ‘ ê²½ê³ : {'ë°œìƒ' if warning else 'ì—†ìŒ'}

[ìœ„í—˜ í‰ê°€] {risk}
{summary}

[ê¶Œì¥ ì¡°ì¹˜]
- {action}
"""

def generate_report_llm(fire_count:int, person_count:int, warning:bool, base_text:str)->str:
    """
    GOOGLE_API_KEYê°€ ìˆìœ¼ë©´ Geminië¡œ ìƒí™©-ë§ì¶¤ ê°„ê²° ìš”ì•½ ìƒì„±.
    - base_text(ê·œì¹™ ê¸°ë°˜)ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µí•´ ê³¼ì¥ ë°©ì§€
    - ì‹¤íŒ¨/í‚¤ì—†ìŒ => base_text ë°˜í™˜
    """
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key:
        return base_text
    try:
        from google import genai
        from google.genai.types import GenerateContentConfig
        client = genai.Client(api_key=api_key)

        prompt = (
            "ë‹¹ì‹ ì€ ê³¼ì¥ì„ í”¼í•˜ê³  í˜„ì¥ì„ ì°¨ë¶„íˆ ì „ë‹¬í•˜ëŠ” ì•ˆì „ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n"
            "ë‹¤ìŒ ê·œì¹™ ê¸°ë°˜ ìš”ì•½ì„ ì¡´ì¤‘í•˜ë˜ í‘œí˜„ë§Œ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.\n"
            "ì†Œê·œëª¨ í™”ì—¼(ì˜ˆ: ë“œëŸ¼í†µì— ë‚˜ë¬´ íƒœì›€)ì€ 'ì£¼ì˜' ìˆ˜ì¤€ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n"
            "ë¶ˆí•„ìš”í•œ ê³µí¬ ì¡°ì„± ê¸ˆì§€, í•œê¸€ 5~7ë¬¸ì¥ ë‚´.\n\n"
            f"ê·œì¹™ ê¸°ë°˜ ìš”ì•½:\n{base_text}\n\n"
            f"íƒì§€ì¹˜: í™”ì¬={fire_count}, ì¸ì›={person_count}, ê·¼ì ‘ê²½ê³ ={'Y' if warning else 'N'}\n"
            "ì¶œë ¥: ìƒí™© ìš”ì•½ / ìœ„í—˜ í‰ê°€(ì•ˆì „Â·ì£¼ì˜Â·ê²½ê³ Â·ì‹¬ê° ì¤‘) / ê¶Œì¥ ì¡°ì¹˜(ìµœì†Œí•œ)"
        )

        resp = client.models.generate_content(
            model="gemini-2.0-flash",  # 1.5ì—ì„œ 404 ë‚¬ë˜ ì´ë ¥ â†’ 2.0 ê¶Œì¥
            contents=prompt,
            config=GenerateContentConfig(max_output_tokens=400),
        )
        text = (resp.text or "").strip()
        return text or base_text
    except Exception:
        return base_text  # í´ë°±

# -------------------------------------------------------
# ëª¨ë¸ ë¡œë”©(ìºì‹œ)
# -------------------------------------------------------
@st.cache_resource
def load_models(fire_pt_path: str, person_pt_path: str):
    fire_model = fire_detector.load_fire_model(fire_pt_path)
    person_model = person_detector.load_person_model(person_pt_path)
    return fire_model, person_model

def detect_once(frame_bgr: np.ndarray, fire_model, person_model, proximity_px:int):
    fire_boxes   = fire_detector.detect_fire(frame_bgr, fire_model) or []
    person_boxes = person_detector.detect_person(frame_bgr, person_model) or []
    warning = False
    for fb in fire_boxes:
        for pb in person_boxes:
            if center_distance(fb, pb) <= proximity_px:
                warning = True
                break
        if warning: break
    annotated = draw_boxes(frame_bgr, fire_boxes, person_boxes, warning)
    return annotated, len(fire_boxes), len(person_boxes), warning

# -------------------------------------------------------
# UI
# -------------------------------------------------------
st.title("ğŸ”¥ ì‹¤ì‹œê°„ í™”ì¬/ì¸ëª… ê°ì§€")

# (ë””ë²„ê·¸) ë²„ì „ ì¶œë ¥ â€” ì‹¤ì œ ë°°í¬ ì‹œ ì œê±° ê°€ëŠ¥
try:
    import streamlit_webrtc, streamlit
    st.caption(f"ST {streamlit.__version__} | WRTC {streamlit_webrtc.__version__}")
except Exception:
    pass

# 0) ëª¨ë¸ ë¡œë”©
try:
    with st.spinner("AI ëª¨ë¸ ë¡œë”© ì¤‘..."):
        fire_model, person_model = load_models(FIRE_PT, PERSON_PT)
    st.success("ëª¨ë¸ ë¡œë”© ì™„ë£Œ âœ…")
except Exception as e:
    st.error("AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ âŒ .pt íŒŒì¼ê³¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.exception(e)
    st.stop()

mode = st.radio("ëª¨ë“œ ì„ íƒ", ["ì›¹ìº ", "ì´ë¯¸ì§€ ì—…ë¡œë“œ", "ë™ì˜ìƒ ì—…ë¡œë“œ"], horizontal=True)

# ===== ìƒíƒœ ë³´ë“œ(ì›¹ìº ) =====
status_fire = st.empty(); status_person = st.empty(); status_warn = st.empty()

# =========================
# 1) ì›¹ìº 
# =========================
if mode == "ì›¹ìº ":
    st.subheader("ì›¹ìº  ì‹¤ì‹œê°„ ê°ì§€")
    proximity_px = st.slider("ìœ„í—˜ ê·¼ì ‘ ê±°ë¦¬(px)", 50, 500, PROXIMITY_PX_DEFAULT)

    # ë¦¬í¬íŠ¸ ìƒíƒœ
    if "report_text" not in st.session_state: st.session_state.report_text = ""
    if "report_done" not in st.session_state: st.session_state.report_done = False

    def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
        frm = frame.to_ndarray(format="bgr24")
        frm = cv2.flip(frm, 1)
        annotated, f_cnt, p_cnt, warn = detect_once(frm, fire_model, person_model, proximity_px)

        # ìƒíƒœ ë³´ë“œ
        status_fire.metric("íƒì§€ëœ í™”ì¬", f_cnt)
        status_person.metric("íƒì§€ëœ ì¸ì›", p_cnt)
        status_warn.metric("ê·¼ì ‘ ê²½ê³ ", "ë°œìƒ" if warn else "ì—†ìŒ")

        # ê²½ê³  ìµœì´ˆ ë°œìƒ ì‹œ 1íšŒ LLM ë¦¬í¬íŠ¸(í´ë°± í¬í•¨)
        if warn and not st.session_state.report_done:
            base = rule_based_report(f_cnt, p_cnt, warn)
            st.session_state.report_text = generate_report_llm(f_cnt, p_cnt, warn, base)
            st.session_state.report_done = True

        return av.VideoFrame.from_ndarray(annotated, format="bgr24")

    ctx = webrtc_streamer(
        key="webcam",
        mode=WebRtcMode.SENDRECV,
        video_frame_callback=video_frame_callback,
        media_stream_constraints={"video": True, "audio": False},
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        async_processing=True,
    )

    if not ctx or not ctx.state.playing:
        st.info("ì¢Œí•˜ë‹¨ **START** ë²„íŠ¼ í´ë¦­ í›„, ë¸Œë¼ìš°ì €ì˜ **ì¹´ë©”ë¼ ê¶Œí•œ í—ˆìš©**ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

    if st.session_state.report_done and st.session_state.report_text:
        st.warning("ğŸš¨ ìœ„í—˜ ìƒí™© ê°ì§€ë¨. ì•„ë˜ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.text_area("AI ë¦¬í¬íŠ¸(ê³¼ì¥ ê¸ˆì§€, ìƒí™© ë§ì¶¤)", st.session_state.report_text, height=260)
        c1, c2 = st.columns(2)
        if c1.button("ë¦¬í¬íŠ¸ ì´ˆê¸°í™”"):
            st.session_state.report_text = ""; st.session_state.report_done = False; st.rerun()
        if c2.button("ê·¼ì ‘ ì„ê³„ê°’ +20px"):
            proximity_px = min(500, proximity_px + 20)
            st.toast(f"ì„ê³„ê°’ì„ {proximity_px-20} â†’ {proximity_px}pxë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.")

# =========================
# 2) ì´ë¯¸ì§€ ì—…ë¡œë“œ
# =========================
elif mode == "ì´ë¯¸ì§€ ì—…ë¡œë“œ":
    st.subheader("ì´ë¯¸ì§€ ì—…ë¡œë“œ ë¶„ì„")
    file = st.file_uploader("ì´ë¯¸ì§€ ì„ íƒ(jpg/png)", type=["jpg","jpeg","png"])
    proximity_px = st.slider("ìœ„í—˜ ê·¼ì ‘ ê±°ë¦¬(px)", 50, 500, PROXIMITY_PX_DEFAULT, key="imgprox")
    if file:
        file_bytes = np.frombuffer(file.read(), np.uint8)
        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        annotated, f_cnt, p_cnt, warn = detect_once(img, fire_model, person_model, proximity_px)
        st.image(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB), caption="ë¶„ì„ ê²°ê³¼", use_container_width=True)
        base = rule_based_report(f_cnt, p_cnt, warn)
        st.markdown(generate_report_llm(f_cnt, p_cnt, warn, base))

# =========================
# 3) ë™ì˜ìƒ ì—…ë¡œë“œ
# =========================
else:
    st.subheader("ë™ì˜ìƒ ì—…ë¡œë“œ ë¶„ì„")
    file = st.file_uploader("ë™ì˜ìƒ ì„ íƒ(mp4/avi/mov)", type=["mp4","avi","mov"])
    proximity_px = st.slider("ìœ„í—˜ ê·¼ì ‘ ê±°ë¦¬(px)", 50, 500, PROXIMITY_PX_DEFAULT, key="vidprox")
    if file:
        # ì„ì‹œ ì €ì¥ â†’ OpenCV ì²˜ë¦¬
        tmp_path = os.path.abspath("uploaded_video.tmp")
        with open(tmp_path, "wb") as f: f.write(file.read())
        cap = cv2.VideoCapture(tmp_path)

        viewer = st.empty()
        info = st.empty()
        frame_count = 0
        fire_total = 0
        person_total = 0
        warn_any = False

        while cap.isOpened():
            ok, frame = cap.read()
            if not ok: break
            frame_count += 1
            annotated, f_cnt, p_cnt, warn = detect_once(frame, fire_model, person_model, proximity_px)
            fire_total += f_cnt; person_total += p_cnt; warn_any = warn_any or warn

            viewer.image(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB), use_container_width=True)
            info.text(f"í”„ë ˆì„: {frame_count} | í™”ì¬:{f_cnt} ì¸ì›:{p_cnt} ê²½ê³ :{'Y' if warn else 'N'}")
            cv2.waitKey(1)

        cap.release()
        os.remove(tmp_path)
        st.success("ë¶„ì„ ì™„ë£Œ")
        base = rule_based_report(fire_total, person_total, warn_any)
        st.markdown(generate_report_llm(fire_total, person_total, warn_any, base))
