import streamlit as st
import cv2
import fire_detector
import person_detector
import google.generativeai as genai
import numpy as np
import tempfile
from PIL import Image
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import asyncio

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="AI í™”ì¬ ë° ì¸ëª… ì•ˆì „ ì‹œìŠ¤í…œ",
    page_icon="ğŸš¨",
    layout="wide",
)

# --- ì•± ì œëª© ---
st.title("ğŸš¨ AI í™”ì¬ ë° ì¸ëª… ê°ì§€ ì‹œìŠ¤í…œ")
st.markdown("ì´ë¯¸ì§€/ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì‹¤ì‹œê°„ ì›¹ìº ì„ í†µí•´ í™”ì¬ ë° ì¸ëª… ìœ„í—˜ì„ ê°ì§€í•˜ê³  AI ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

# --- ì‚¬ì´ë“œë°” ì„¤ì • ---
st.sidebar.title("âš™ï¸ ì œì–´íŒ")

# Gemini API í‚¤ ì…ë ¥
st.sidebar.header("API í‚¤ ì„¤ì •")
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
except (KeyError, FileNotFoundError):
    GOOGLE_API_KEY = st.sidebar.text_input(
        "Google Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password", help="API í‚¤ê°€ ì—†ìœ¼ë©´ ë¦¬í¬íŠ¸ ìƒì„±ì´ ë¶ˆê°€í•©ë‹ˆë‹¤."
    )

# ì‘ì—… ëª¨ë“œ ì„ íƒ
app_mode = st.sidebar.selectbox(
    "ì‘ì—… ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”",
    ["ì‹¤ì‹œê°„ ì›¹ìº  ê°ì§€", "íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„"]
)
st.sidebar.markdown("---")

# --- ëª¨ë¸ ë¡œë”© ---
@st.cache_resource
def load_models():
    """AI ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (ìºì‹±í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”)"""
    try:
        fire_model = fire_detector.load_fire_model('fire2.pt')
        person_model = person_detector.load_person_model('yolov8n.pt')
        return fire_model, person_model
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

with st.spinner('AI ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...'):
    fire_model, person_model = load_models()

if fire_model is None or person_model is None:
    st.error("AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. GitHubì— .pt íŒŒì¼ë“¤ì´ ì˜¬ë°”ë¥´ê²Œ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- ê³µí†µ í•¨ìˆ˜: í”„ë ˆì„ ë¶„ì„ ë° ì‹œê°í™” ---
def analyze_and_draw_on_frame(frame, proximity_threshold):
    """í”„ë ˆì„ ë‚´ì—ì„œ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ìœ„í—˜ìƒí™©ì„ ë¶„ì„í•˜ì—¬ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    fire_boxes = fire_detector.detect_fire(frame, fire_model)
    person_boxes = person_detector.detect_person(frame, person_model)
    is_warning = False

    if fire_boxes:
        for f_box in fire_boxes:
            cv2.rectangle(frame, (f_box[0], f_box[1]), (f_box[2], f_box[3]), (0, 0, 255), 3)
            cv2.putText(frame, 'Fire', (f_box[0], f_box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
            for p_box in person_boxes:
                fire_center_x = f_box[0] + (f_box[2] - f_box[0]) / 2
                person_center_x = p_box[0] + (p_box[2] - p_box[0]) / 2
                if abs(fire_center_x - person_center_x) < proximity_threshold:
                    is_warning = True
                    cv2.rectangle(frame, (p_box[0], p_box[1]), (p_box[2], p_box[3]), (0, 165, 255), 4)
                else:
                    cv2.rectangle(frame, (p_box[0], p_box[1]), (p_box[2], p_box[3]), (255, 0, 0), 2)
                cv2.putText(frame, 'Person', (p_box[0], p_box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
    else:
        for p_box in person_boxes:
            cv2.rectangle(frame, (p_box[0], p_box[1]), (p_box[2], p_box[3]), (255, 0, 0), 2)
            cv2.putText(frame, 'Person', (p_box[0], p_box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)

    if is_warning:
        cv2.putText(frame, "WARNING: Person Near Fire!", (50, 60), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 255), 3)
        
    return frame, len(fire_boxes), len(person_boxes), is_warning

# --- ê³µí†µ í•¨ìˆ˜: AI ë¦¬í¬íŠ¸ ìƒì„± ---
def generate_report(fire_count, person_count, is_warning, image_frame):
    """íƒì§€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ Gemini AI ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not GOOGLE_API_KEY:
        st.error("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
        pil_image = Image.fromarray(cv2.cvtColor(image_frame, cv2.COLOR_BGR2RGB))

        # ì‚¬ìš©ìë‹˜ì´ ì„ í˜¸í•˜ì…¨ë˜ ìƒì„¸ í”„ë¡¬í”„íŠ¸
        prompt_parts = [
            pil_image,
            "ë‹¹ì‹ ì€ CCTV ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” AI ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
            "\n## ì§€ì‹œì‚¬í•­",
            "ì²¨ë¶€ëœ ì´ë¯¸ì§€ì™€ ì•„ë˜ ìš”ì•½ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì•ˆì „ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.",
            "\n## ë¶„ì„ ë°ì´í„°",
            f"- í™”ì¬ ê°ì²´ ìˆ˜: {fire_count}",
            f"- ì‚¬ëŒ ê°ì²´ ìˆ˜: {person_count}",
            f"- ìœ„í—˜ ê²½ê³  (ì‚¬ëŒ-í™”ì¬ ê·¼ì ‘): {'ë°œìƒ' if is_warning else 'ì—†ìŒ'}",
            "\n## ë¶„ì„ ê°€ì´ë“œë¼ì¸",
            "1. **[ìƒí™© ë§¥ë½ íŒŒì•…]** ì´ë¯¸ì§€ ì† ë¶ˆì´ í†µì œëœ ìƒí™©(ì˜ˆ: ë“œëŸ¼í†µ ì•ˆì˜ ëª¨ë‹¥ë¶ˆ, ìº í”„íŒŒì´ì–´)ì¸ì§€, í†µì œë˜ì§€ ì•Šì€ ìœ„í—˜í•œ í™”ì¬(ì˜ˆ: ê±´ë¬¼ í™”ì¬, ì‚°ë¶ˆ)ì¸ì§€ ë¨¼ì € íŒë‹¨í•˜ì„¸ìš”. ì£¼ë³€ í™˜ê²½ê³¼ ì‚¬ëŒë“¤ì˜ í–‰ë™ì„ ê·¼ê±°ë¡œ ì œì‹œí•˜ì„¸ìš”.",
            "2. **[ìœ„í—˜ë„ í‰ê°€]** ìœ„ ë§¥ë½ì— ë”°ë¼ ìœ„í—˜ë„ë¥¼ 'ì•ˆì „', 'ì£¼ì˜', 'ê²½ê³ ', 'ì‹¬ê°' 4ë‹¨ê³„ë¡œ í‰ê°€í•˜ê³ , ê·¸ ì´ìœ ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.",
            "3. **[ê¶Œì¥ ì¡°ì¹˜]** í‰ê°€ëœ ìœ„í—˜ë„ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì¡°ì¹˜ë¥¼ 1~2ê°€ì§€ ì œì•ˆí•˜ì„¸ìš”. 'ê²½ê³ ' ë˜ëŠ” 'ì‹¬ê°' ë‹¨ê³„ì¼ ê²½ìš°, êµ¬ì²´ì ì¸ ëŒ€í”¼ ìš”ë ¹ì„ ë°˜ë“œì‹œ í¬í•¨ì‹œí‚¤ì„¸ìš”.",
            "\nìœ„ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
        ]
        
        model = genai.GenerativeModel('gemini-2.5-flash') 
        response = model.generate_content(prompt_parts)
        return response.text
    except Exception as e:
        st.error(f"AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# --- ëª¨ë“œ 1: ì‹¤ì‹œê°„ ì›¹ìº  ê°ì§€ ---
if app_mode == "ì‹¤ì‹œê°„ ì›¹ìº  ê°ì§€":
    st.header("ì‹¤ì‹œê°„ ì›¹ìº  ê°ì§€")
    st.info("ì›¹ìº ì„ ì¼œê³  ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì²´ë¥¼ íƒì§€í•©ë‹ˆë‹¤. 'START' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    
    proximity_threshold = st.slider(
        "ìœ„í—˜ ê·¼ì ‘ ê±°ë¦¬ ì„¤ì • (px)", 50, 500, 150,
        help="í™”ì¬ì™€ ì‚¬ëŒ ì‚¬ì´ì˜ ê±°ë¦¬ê°€ ì´ ê°’ë³´ë‹¤ ê°€ê¹Œìš°ë©´ ìœ„í—˜ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤."
    )

    if 'report_generated' not in st.session_state:
        st.session_state.report_generated = False
    if 'report_text' not in st.session_state:
        st.session_state.report_text = ""

    # ì›¹ìº  ì‘ë™ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë””ë²„ê¹… ì¶”ê°€
    class VideoTransformer(VideoTransformerBase):
        def __init__(self):
            self.proximity_threshold = proximity_threshold

        def recv(self, frame):
            if frame is None:  # í”„ë ˆì„ì´ Noneì¼ ê²½ìš° ì˜¤ë¥˜ ì²˜ë¦¬
                st.error("ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ìˆ˜ì‹ í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
                return None
            try:
                frm = frame.to_ndarray(format="bgr24")
                annotated_frame, f_count, p_count, is_warning = analyze_and_draw_on_frame(frm, self.proximity_threshold)
                
                if is_warning and not st.session_state.report_generated:
                    report = generate_report(f_count, p_count, is_warning, annotated_frame)
                    if report:
                        st.session_state.report_text = report
                        st.session_state.report_generated = True
                
                return annotated_frame
            except Exception as e:
                st.error(f"í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                return None

    # asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì´ˆê¸°í™” ì¶”ê°€ (ì›¹ìº  ì‘ë™ ë¬¸ì œ í•´ê²° ì‹œë„)
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    webrtc_streamer(
        key="webcam",
        video_processor_factory=VideoTransformer,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

    if st.session_state.report_generated:
        st.warning("ğŸš¨ ìœ„í—˜ ìƒí™©ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ AI ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.text_area("AI ìƒì„± ë¦¬í¬íŠ¸", st.session_state.report_text, height=300)
        if st.button("ë¦¬í¬íŠ¸ ì´ˆê¸°í™” ë° ë‹¤ì‹œ ê°ì§€"):
            st.session_state.report_generated = False
            st.session_state.report_text = ""
            st.rerun()

# --- ëª¨ë“œ 2: íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„ ---
elif app_mode == "íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„":
    st.header("íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„")
    uploaded_file = st.file_uploader(
        "ì´ë¯¸ì§€ ë˜ëŠ” ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        type=["jpg", "jpeg", "png", "mp4", "mov", "avi"]
    )
    
    if uploaded_file is not None:
        file_type = uploaded_file.type.split('/')[0]
        
        if file_type == "image":
            image = Image.open(uploaded_file)
            frame = np.array(image)
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

            annotated_frame, f_count, p_count, warn = analyze_and_draw_on_frame(frame, 150)
            
            st.image(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB), caption="ë¶„ì„ëœ ì´ë¯¸ì§€", use_container_width=True)
            
            st.markdown("---")
            st.subheader("ğŸ“‹ ë¶„ì„ ê²°ê³¼")
            st.write(f"ğŸ”¥ íƒì§€ëœ í™”ì¬: **{f_count}** ê±´")
            st.write(f"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ íƒì§€ëœ ì¸ì›: **{p_count}** ëª…")
            st.warning("ğŸš¨ ìœ„í—˜ ìƒí™©(í™”ì¬ ê·¼ì ‘ ì¸ì›) ë°œìƒ!" if warn else "âœ… ìœ„í—˜ ìƒí™© ì—†ìŒ.")
            
            if st.button("AI ì•ˆì „ ë¦¬í¬íŠ¸ ìƒì„±"):
                with st.spinner("AIê°€ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    report = generate_report(f_count, p_count, warn, annotated_frame)
                    if report:
                        st.text_area("AI ìƒì„± ë¦¬í¬íŠ¸", report, height=300)

        elif file_type == "video":
            tfile = tempfile.NamedTemporaryFile(delete=False) 
            tfile.write(uploaded_file.read())
            
            video_capture = cv2.VideoCapture(tfile.name)
            frame_placeholder = st.empty()
            
            total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
            progress_bar = st.progress(0)
            
            max_fire, max_person, is_any_warning = 0, 0, False
            last_warn_frame = None

            for i in range(total_frames):
                success, frame = video_capture.read()
                if not success:
                    break
                
                annotated_frame, f_count, p_count, warn = analyze_and_draw_on_frame(frame, 150)
                
                max_fire = max(max_fire, f_count)
                max_person = max(max_person, p_count)
                if warn: 
                    is_any_warning = True
                    last_warn_frame = annotated_frame.copy()

                frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                frame_placeholder.image(frame_rgb, caption=f"ë™ì˜ìƒ ë¶„ì„ ì¤‘... ({i+1}/{total_frames})", use_container_width=True)
                progress_bar.progress((i + 1) / total_frames)

            video_capture.release()
            
            st.success("ë™ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.markdown("---")
            st.subheader("ğŸ“‹ ì „ì²´ ë™ì˜ìƒ ë¶„ì„ ìš”ì•½")
            st.write(f"ğŸ”¥ íƒì§€ëœ ìµœëŒ€ í™”ì¬ ìˆ˜: **{max_fire}** ê±´")
            st.write(f"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ íƒì§€ëœ ìµœëŒ€ ì¸ì› ìˆ˜: **{max_person}** ëª…")
            st.warning("ğŸš¨ ìœ„í—˜ ìƒí™©(í™”ì¬ ê·¼ì ‘ ì¸ì›)ì´ í•œ ë²ˆ ì´ìƒ ë°œìƒí–ˆìŠµë‹ˆë‹¤!" if is_any_warning else "âœ… ì „ì²´ ì˜ìƒì—ì„œ ìœ„í—˜ ìƒí™©ì€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            if st.button("AI ì•ˆì „ ë¦¬í¬íŠ¸ ìƒì„±"):
                report_frame = last_warn_frame if is_any_warning and last_warn_frame is not None else annotated_frame
                with st.spinner("AIê°€ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    report = generate_report(max_fire, max_person, is_any_warning, report_frame)
                    if report:
                        st.text_area("AI ìƒì„± ë¦¬í¬íŠ¸", report, height=300)
