import streamlit as st
import cv2
import fire_detector
import person_detector
import google.generativeai as genai
import numpy as np
import tempfile
from PIL import Image

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="AI í™”ì¬ ë° ì¸ëª… ì•ˆì „ ì‹œìŠ¤í…œ",
    page_icon="ğŸš¨",
    layout="wide",
)

# --- ì•± ì œëª© ---
st.title("ğŸš¨ AI í™”ì¬ ë° ì¸ëª… ê°ì§€ ì‹œìŠ¤í…œ(CCTVìš© ëª¨ë¸)")
st.markdown("---")

# --- ì‚¬ì´ë“œë°” ì„¤ì • ---
st.sidebar.title("âš™ï¸ ì œì–´íŒ")

# Gemini API í‚¤ ì…ë ¥
st.sidebar.header("íƒì§€ ëª¨ë“œ")
try:
    # Try to get the key from Streamlit's secrets
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
except (KeyError, FileNotFoundError):
    GOOGLE_API_KEY = st.sidebar.text_input(
        "Google Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password", help="API í‚¤ê°€ ì—†ìœ¼ë©´ ë¦¬í¬íŠ¸ ìƒì„±ì´ ë¶ˆê°€í•©ë‹ˆë‹¤."
    )

# ì‘ì—… ëª¨ë“œ ì„ íƒ
app_mode = st.sidebar.selectbox(
    "ì‘ì—… ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”",
    ["ì‹¤ì‹œê°„ ì›¹ìº  ê°ì§€", "íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„"]
)
st.sidebar.markdown("---")

# --- ëª¨ë¸ ë¡œë”© ---
@st.cache_resource
def load_models():
    """AI ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (ìºì‹±í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”)"""
    fire_model = fire_detector.load_fire_model('fire2.pt')
    person_model = person_detector.load_person_model('yolov5s.pt')
    return fire_model, person_model

with st.spinner('AI ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...'):
    fire_model, person_model = load_models()

if fire_model is None or person_model is None:
    st.error("AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. .pt íŒŒì¼ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- ê³µí†µ í•¨ìˆ˜: í”„ë ˆì„ ë¶„ì„ ë° ì‹œê°í™” ---
def analyze_and_draw_on_frame(frame, proximity_threshold):
    """í”„ë ˆì„ ë‚´ì—ì„œ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ìœ„í—˜ìƒí™©ì„ ë¶„ì„í•˜ì—¬ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    fire_boxes = fire_detector.detect_fire(frame, fire_model)
    person_boxes = person_detector.detect_person(frame, person_model)
    is_warning = False

    if fire_boxes:
        for f_box in fire_boxes:
            cv2.rectangle(frame, (f_box[0], f_box[1]), (f_box[2], f_box[3]), (0, 0, 255), 3)
            cv2.putText(frame, 'Fire', (f_box[0], f_box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
            for p_box in person_boxes:
                fire_center_x = f_box[0] + (f_box[2] - f_box[0]) / 2
                person_center_x = p_box[0] + (p_box[2] - p_box[0]) / 2
                if abs(fire_center_x - person_center_x) < proximity_threshold:
                    is_warning = True
                    cv2.rectangle(frame, (p_box[0], p_box[1]), (p_box[2], p_box[3]), (0, 165, 255), 4)
                else:
                    cv2.rectangle(frame, (p_box[0], p_box[1]), (p_box[2], p_box[3]), (255, 0, 0), 2)
                cv2.putText(frame, 'Person', (p_box[0], p_box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
    else:
        for p_box in person_boxes:
            cv2.rectangle(frame, (p_box[0], p_box[1]), (p_box[2], p_box[3]), (255, 0, 0), 2)
            cv2.putText(frame, 'Person', (p_box[0], p_box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)

    if is_warning:
        cv2.putText(frame, "WARNING: Person Near Fire!", (50, 60), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 255), 3)
        
    return frame, len(fire_boxes), len(person_boxes), is_warning

# --- ê³µí†µ í•¨ìˆ˜: AI ë¦¬í¬íŠ¸ ìƒì„± ---
def generate_report(fire_count, person_count, is_warning, image_frame):
    """íƒì§€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ Gemini AI ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not GOOGLE_API_KEY:
        st.error("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
        
        # PIL Imageë¡œ ë³€í™˜
        pil_image = Image.fromarray(cv2.cvtColor(image_frame, cv2.COLOR_BGR2RGB))

        # ë¦¬í¬íŠ¸ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì•„ë˜ 2ë²ˆì—ì„œ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ë°”ê¿€ ì˜ˆì •)
        prompt_parts = [
    pil_image,
    "ë‹¹ì‹ ì€ CCTV ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” AI ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
    "\n## ì§€ì‹œì‚¬í•­",
    "ì²¨ë¶€ëœ ì´ë¯¸ì§€ì™€ ì•„ë˜ ìš”ì•½ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì•ˆì „ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.",
    
    "\n## ë¶„ì„ ë°ì´í„°",
    f"- í™”ì¬ ê°ì²´ ìˆ˜: {fire_count}",
    f"- ì‚¬ëŒ ê°ì²´ ìˆ˜: {person_count}",
    f"- ìœ„í—˜ ê²½ê³  (ì‚¬ëŒ-í™”ì¬ ê·¼ì ‘): {'ë°œìƒ' if is_warning else 'ì—†ìŒ'}",

    "\n## ë¶„ì„ ê°€ì´ë“œë¼ì¸",
    "1.  **[ìƒí™© ë§¥ë½ íŒŒì•…]** ì´ë¯¸ì§€ ì† ë¶ˆì´ í†µì œëœ ìƒí™©(ì˜ˆ: ë“œëŸ¼í†µ ì•ˆì˜ ëª¨ë‹¥ë¶ˆ, ìº í”„íŒŒì´ì–´)ì¸ì§€, í†µì œë˜ì§€ ì•Šì€ ìœ„í—˜í•œ í™”ì¬(ì˜ˆ: ê±´ë¬¼ í™”ì¬, ì‚°ë¶ˆ)ì¸ì§€ ë¨¼ì € íŒë‹¨í•˜ì„¸ìš”. ì£¼ë³€ í™˜ê²½(ì‹¤ë‚´/ì‹¤ì™¸)ê³¼ ì‚¬ëŒë“¤ì˜ í–‰ë™(ë¶ˆì„ ì¬ëŠ” ì¤‘/ëŒ€í”¼ ì¤‘)ì„ ê·¼ê±°ë¡œ ì œì‹œí•˜ì„¸ìš”.",
    "2.  **[ìœ„í—˜ë„ í‰ê°€]** ìœ„ ë§¥ë½ì— ë”°ë¼ ìœ„í—˜ë„ë¥¼ 'ì•ˆì „', 'ì£¼ì˜', 'ê²½ê³ ', 'ì‹¬ê°' 4ë‹¨ê³„ë¡œ í‰ê°€í•˜ê³ , ê·¸ ì´ìœ ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”. (ì˜ˆ: 'ë“œëŸ¼í†µ ë‚´ë¶€ì˜ í†µì œëœ ë¶ˆì´ë©° ì£¼ë³€ì— ì¸í™”ë¬¼ì§ˆì´ ì—†ì–´ ì•ˆì „ ë‹¨ê³„ì„')",
    "3.  **[ê¶Œì¥ ì¡°ì¹˜]** í‰ê°€ëœ ìœ„í—˜ë„ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì¡°ì¹˜ë¥¼ 1~2ê°€ì§€ ì œì•ˆí•˜ì„¸ìš”. ì‹¬ê°í•œ ìƒí™©ì´ ì•„ë‹ˆë¼ë©´, 'ì•ˆì „ê±°ë¦¬ ìœ ì§€', 'ì†Œí™”ê¸° ìœ„ì¹˜ í™•ì¸' ë“± ì˜ˆë°©ì  ì¡°ì¹˜ë¥¼ ê¶Œê³ í•˜ì„¸ìš”. ê³¼ì¥ëœ ê²½ê³ ëŠ” í”¼í•˜ì„¸ìš”.",
    
    "\nìœ„ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
]
        
        # [ê¶Œì¥] ë©€í‹°ëª¨ë‹¬ì„ ì§€ì›í•˜ëŠ” ìµœì‹  ëª¨ë¸ë¡œ ë³€ê²½
        model = genai.GenerativeModel('gemini-2.5-flash') 
        response = model.generate_content(prompt_parts) # promptê°€ ì•„ë‹Œ prompt_partsë¥¼ ì „ë‹¬
        return response.text
    except Exception as e:
        st.error(f"AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# --- ëª¨ë“œ 1: ì‹¤ì‹œê°„ ì›¹ìº  ê°ì§€ ---
if app_mode == "ì‹¤ì‹œê°„ ì›¹ìº  ê°ì§€":
    st.header("ì‹¤ì‹œê°„ ì›¹ìº  ê°ì§€")
    run_webcam = st.toggle("ì›¹ìº  ì‹¤í–‰", value=True)
    proximity_threshold = st.slider(
        "ìœ„í—˜ ê·¼ì ‘ ê±°ë¦¬ ì„¤ì • (px)", 50, 500, 150, 
        help="í™”ì¬ì™€ ì‚¬ëŒ ì‚¬ì´ì˜ ê±°ë¦¬ê°€ ì´ ê°’ë³´ë‹¤ ê°€ê¹Œìš°ë©´ ìœ„í—˜ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤."
    )
    
    # --- UI í”Œë ˆì´ìŠ¤í™€ë” ì¶”ê°€ ---
    frame_placeholder = st.empty()
    report_placeholder = st.empty() # AI ë¦¬í¬íŠ¸ë¥¼ í‘œì‹œí•  ê³µê°„

    if run_webcam:
        video_capture = cv2.VideoCapture(0)
        
        # --- ë¦¬í¬íŠ¸ ì¤‘ë³µ ìƒì„±ì„ ë§‰ê¸° ìœ„í•œ ìƒíƒœ ë³€ìˆ˜ ---
        report_generated = False 

        while video_capture.isOpened():
            success, frame = video_capture.read()
            if not success:
                st.error("ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            # í”„ë ˆì„ ë¶„ì„ ë° ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            annotated_frame, f_count, p_count, is_warning = analyze_and_draw_on_frame(frame, proximity_threshold)
            
            # í™”ë©´ ì—…ë°ì´íŠ¸
            frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
            frame_placeholder.image(frame_rgb, caption="ì‹¤ì‹œê°„ ê°ì§€ ì¤‘...",  use_container_width=True)
            
            # --- AI ë¦¬í¬íŠ¸ ìƒì„± ë¡œì§ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„) ---
            # ìœ„í—˜ ìƒí™©ì´ ë°œìƒí–ˆê³ , ì•„ì§ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ë‹¤ë©´
            if is_warning and not report_generated:
                with st.spinner("âš ï¸ ìœ„í—˜ ìƒí™© ê°ì§€! AI ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..."):
                    report = generate_report(f_count, p_count, is_warning, annotated_frame)
                    if report:
                        # ë¦¬í¬íŠ¸ í‘œì‹œ ì˜ì—­ì— ê²°ê³¼ ì¶œë ¥
                        report_placeholder.text_area("AI ìƒì„± ë¦¬í¬íŠ¸", report, height=300)
                        report_generated = True # ë¦¬í¬íŠ¸ ìƒì„±ë¨ì„ í‘œì‹œ (ì¤‘ë³µ ë°©ì§€)

        video_capture.release()
    else:
        frame_placeholder.info("ì›¹ìº  ì‹¤í–‰ ë²„íŠ¼ì„ ì¼œì„œ ê°ì§€ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")

# --- ëª¨ë“œ 2: íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„ ---
elif app_mode == "íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„":
    st.header("íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„")
    uploaded_file = st.file_uploader(
        "ì´ë¯¸ì§€ ë˜ëŠ” ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        type=["jpg", "jpeg", "png", "mp4", "mov", "avi"]
    )
    
    if uploaded_file is not None:
        file_type = uploaded_file.type.split('/')[0]
        
        # --- ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ ---
        if file_type == "image":
            image = Image.open(uploaded_file)
            frame = np.array(image)
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR) # OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜

            annotated_frame, f_count, p_count, warn = analyze_and_draw_on_frame(frame, 150)
            
            st.image(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB), caption="ë¶„ì„ëœ ì´ë¯¸ì§€", use_container_width=True)
            
            st.markdown("---")
            st.subheader("ğŸ“‹ ë¶„ì„ ê²°ê³¼")
            st.write(f"ğŸ”¥ íƒì§€ëœ í™”ì¬: **{f_count}** ê±´")
            st.write(f"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ íƒì§€ëœ ì¸ì›: **{p_count}** ëª…")
            st.warning("ğŸš¨ ìœ„í—˜ ìƒí™©(í™”ì¬ ê·¼ì ‘ ì¸ì›) ë°œìƒ!" if warn else "âœ… ìœ„í—˜ ìƒí™© ì—†ìŒ.")
            
            if st.button("AI ì•ˆì „ ë¦¬í¬íŠ¸ ìƒì„±"):
                with st.spinner("AIê°€ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    report = generate_report(f_count, p_count, warn, annotated_frame)
                    if report:
                        st.text_area("AI ìƒì„± ë¦¬í¬íŠ¸", report, height=300)

        # --- ë™ì˜ìƒ íŒŒì¼ ì²˜ë¦¬ ---
        elif file_type == "video":
            tfile = tempfile.NamedTemporaryFile(delete=False) 
            tfile.write(uploaded_file.read())
            
            video_capture = cv2.VideoCapture(tfile.name)
            frame_placeholder = st.empty()
            
            total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
            progress_bar = st.progress(0)
            
            max_fire, max_person, is_any_warning = 0, 0, False

            for i in range(total_frames):
                success, frame = video_capture.read()
                if not success:
                    break
                
                annotated_frame, f_count, p_count, warn = analyze_and_draw_on_frame(frame, 150)
                
                # ìµœëŒ€ê°’ ë° ìœ„í—˜ ìƒí™© ì—…ë°ì´íŠ¸
                max_fire = max(max_fire, f_count)
                max_person = max(max_person, p_count)
                if warn: is_any_warning = True

                frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                frame_placeholder.image(frame_rgb, caption=f"ë™ì˜ìƒ ë¶„ì„ ì¤‘... ({i+1}/{total_frames})", use_container_width=True)
                progress_bar.progress((i + 1) / total_frames)

            video_capture.release()
            
            st.success("ë™ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.markdown("---")
            st.subheader("ğŸ“‹ ì „ì²´ ë™ì˜ìƒ ë¶„ì„ ìš”ì•½")
            st.write(f"ğŸ”¥ íƒì§€ëœ ìµœëŒ€ í™”ì¬ ìˆ˜: **{max_fire}** ê±´")
            st.write(f"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ íƒì§€ëœ ìµœëŒ€ ì¸ì› ìˆ˜: **{max_person}** ëª…")
            st.warning("ğŸš¨ ìœ„í—˜ ìƒí™©(í™”ì¬ ê·¼ì ‘ ì¸ì›)ì´ í•œ ë²ˆ ì´ìƒ ë°œìƒí–ˆìŠµë‹ˆë‹¤!" if is_any_warning else "âœ… ì „ì²´ ì˜ìƒì—ì„œ ìœ„í—˜ ìƒí™©ì€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            if st.button("AI ì•ˆì „ ë¦¬í¬íŠ¸ ìƒì„±"):
                with st.spinner("AIê°€ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    report = generate_report(max_fire, max_person, is_any_warning, annotated_frame)
                    if report:
                        st.text_area("AI ìƒì„± ë¦¬í¬íŠ¸", report, height=300)
