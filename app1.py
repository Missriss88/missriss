# app1.py
import os
import math
from typing import Tuple, List

import cv2
import av
import numpy as np
import streamlit as st
# --- Streamlit <-> streamlit-webrtc ë²„ì „ í˜¸í™˜ ì…”ì„ ---
# webrtcê°€ ë‚´ë¶€ì—ì„œ st.experimental_rerun()ì„ í˜¸ì¶œí•˜ëŠ” êµ¬ë²„ì „ì¼ ë•Œ ëŒ€ë¹„
if not hasattr(st, "experimental_rerun") and hasattr(st, "rerun"):
    st.experimental_rerun = st.rerun

from streamlit_webrtc import webrtc_streamer, WebRtcMode

import fire_detector
import person_detector

st.set_page_config(page_title="ì‹¤ì‹œê°„ í™”ì¬/ì¸ëª… ê°ì§€", page_icon="ğŸ”¥", layout="wide")

# -----------------------------
# (ê³ ì •) ëª¨ë¸ ê²½ë¡œ: í•„ìš” ì‹œ ì•„ë˜ ë‘ ì¤„ë§Œ ìˆ˜ì •
# -----------------------------
FIRE_PT   = os.path.abspath("fire2.pt")     # ì˜ˆ: ./fire2.pt
PERSON_PT = os.path.abspath("yolov8n.pt")   # ì˜ˆ: ./yolov8n.pt  (YOLOv5ë¥¼ ì“°ë©´ yolov5s.ptë¡œ)
PROXIMITY_PX = 150                          # í™”ì¬-ì‚¬ëŒ ì¤‘ì‹¬ê±°ë¦¬ ì„ê³„ê°’(px)

# -----------------------------
# ìœ í‹¸
# -----------------------------
def iou_or_center_dist(a, b) -> float:
    ax = (a[0] + a[2]) / 2.0
    ay = (a[1] + a[3]) / 2.0
    bx = (b[0] + b[2]) / 2.0
    by = (b[1] + b[3]) / 2.0
    return math.hypot(ax - bx, ay - by)

# -----------------------------
# ê·œì¹™ ê¸°ë°˜ ë¦¬í¬íŠ¸ (ê³¼ì¥ ê¸ˆì§€)
# -----------------------------
def rule_based_report(fire_count: int, person_count: int, warning: bool) -> str:
    if fire_count == 0 and person_count == 0:
        risk = "ì•ˆì „"
        summary = "í™”ì¬ì™€ ì‚¬ëŒ ëª¨ë‘ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        action = "ë³„ë„ ì¡°ì¹˜ í•„ìš” ì—†ìŠµë‹ˆë‹¤."
    elif fire_count > 0 and person_count == 0:
        risk = "ì£¼ì˜"
        summary = "ì‘ì€ ë¶ˆì´ íƒì§€ë˜ì—ˆì§€ë§Œ ì£¼ë³€ì— ì‚¬ëŒì€ ì—†ìŠµë‹ˆë‹¤."
        action = "ìƒí™©ì„ ê´€ì°°í•˜ì„¸ìš”. í™•ì‚°/ì—°ê¸° ì¦ê°€ ì‹œ ì§„í™” ì¡°ì¹˜ë¥¼ ê³ ë ¤í•˜ì„¸ìš”."
    elif fire_count > 0 and person_count > 0 and not warning:
        risk = "ì£¼ì˜"
        summary = "ë¶ˆì´ ìˆìœ¼ë‚˜ ì‚¬ëŒì€ ì•ˆì „ê±°ë¦¬ì—ì„œ ê´€ì°° ì¤‘ì…ë‹ˆë‹¤."
        action = "ì•ˆì „ê±°ë¦¬ë¥¼ ìœ ì§€í•˜ê³  ì†Œí™”ê¸° ë“± ëŒ€ë¹„ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."
    else:
        risk = "ê²½ê³ "
        summary = "ë¶ˆ ê·¼ì²˜ì—ì„œ ì‚¬ëŒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
        action = "ì¦‰ì‹œ ì•ˆì „ê±°ë¦¬ë¥¼ í™•ë³´í•˜ê³  í•„ìš” ì‹œ ì†Œí™”/ëŒ€í”¼ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”."
    return f"""[ìƒí™© ìš”ì•½]
- í™”ì¬: {fire_count}ê±´ / ì¸ì›: {person_count}ëª… / ê·¼ì ‘ ê²½ê³ : {'ë°œìƒ' if warning else 'ì—†ìŒ'}

[ìœ„í—˜ í‰ê°€] {risk}
{summary}

[ê¶Œì¥ ì¡°ì¹˜]
- {action}
"""

# -----------------------------
# ëª¨ë¸ ë¡œë“œ (ìºì‹œ)
# -----------------------------
@st.cache_resource
def load_models(fire_pt_path: str, person_pt_path: str):
    fire_model = fire_detector.load_fire_model(fire_pt_path)
    person_model = person_detector.load_person_model(person_pt_path)
    return fire_model, person_model

# -----------------------------
# í•œ í”„ë ˆì„ ë¶„ì„ ë° ê·¸ë¦¬ê¸°
# -----------------------------
def analyze_and_draw(
    frame_bgr: np.ndarray,
    fire_model,
    person_model,
    proximity_px: int = PROXIMITY_PX
) -> Tuple[np.ndarray, int, int, bool]:
    # íƒì§€
    fire_boxes: List[List[int]] = fire_detector.detect_fire(frame_bgr, fire_model) or []
    person_boxes: List[List[int]] = person_detector.detect_person(frame_bgr, person_model) or []

    # ê²½ê³  íŒì •(ìµœì†Œ ì¤‘ì‹¬ê±°ë¦¬)
    warning = False
    for fb in fire_boxes:
        for pb in person_boxes:
            if iou_or_center_dist(fb, pb) <= proximity_px:
                warning = True
                break
        if warning: break

    # ê·¸ë¦¬ê¸°
    annotated = frame_bgr.copy()
    for (x1, y1, x2, y2) in fire_boxes:
        cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 0, 255), 2)
        cv2.putText(annotated, "FIRE", (x1, max(0, y1 - 6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
    for (x1, y1, x2, y2) in person_boxes:
        cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 200, 0), 2)
        cv2.putText(annotated, "PERSON", (x1, max(0, y1 - 6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 200, 0), 2)

    if warning:
        h, w = annotated.shape[:2]
        cv2.rectangle(annotated, (0, 0), (w, 36), (0, 0, 255), -1)
        cv2.putText(annotated, "WARNING: PERSON NEAR FIRE",
                    (10, 26), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

    return annotated, len(fire_boxes), len(person_boxes), warning

# -----------------------------
# UI
# -----------------------------
st.title("ğŸ”¥ ì‹¤ì‹œê°„ í™”ì¬/ì¸ëª… ê°ì§€")

# ëª¨ë¸ ë¡œë“œ (ê³ ì • ê²½ë¡œ)
try:
    with st.spinner("AI ëª¨ë¸ ë¡œë”© ì¤‘..."):
        fire_model, person_model = load_models(FIRE_PT, PERSON_PT)
    st.success("ëª¨ë¸ ë¡œë”© ì™„ë£Œ âœ…")
except Exception as e:
    st.error("AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ âŒ .pt íŒŒì¼ê³¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.exception(e)
    st.stop()

st.divider()
st.subheader("ì›¹ìº ")

# ìƒíƒœ ì €ì¥
if "report_text" not in st.session_state:
    st.session_state.report_text = ""
if "report_done" not in st.session_state:
    st.session_state.report_done = False

# ìƒíƒœ í‘œì‹œ
status_fire = st.empty()
status_person = st.empty()
status_warn = st.empty()

# ---- WebRTC ì½œë°± ----
def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
    frm = frame.to_ndarray(format="bgr24")
    frm = cv2.flip(frm, 1)

    annotated, f_cnt, p_cnt, warn = analyze_and_draw(
        frm, fire_model, person_model, PROXIMITY_PX
    )

    # ìƒíƒœ ê°±ì‹ 
    status_fire.metric("íƒì§€ëœ í™”ì¬", f_cnt)
    status_person.metric("íƒì§€ëœ ì¸ì›", p_cnt)
    status_warn.metric("ê·¼ì ‘ ê²½ê³ ", "ë°œìƒ" if warn else "ì—†ìŒ")

    # ê²½ê³  ì²˜ìŒ ë°œìƒ ì‹œ ë¦¬í¬íŠ¸ 1íšŒ ìƒì„±
    if warn and not st.session_state.report_done:
        st.session_state.report_text = rule_based_report(f_cnt, p_cnt, warn)
        st.session_state.report_done = True

    return av.VideoFrame.from_ndarray(annotated, format="bgr24")

# ---- WebRTC ì‹¤í–‰ ----
webrtc_streamer(
    key="webcam",
    mode=WebRtcMode.SENDRECV,
    video_frame_callback=video_frame_callback,
    media_stream_constraints={"video": True, "audio": False},
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    async_processing=True,
)

# ë¦¬í¬íŠ¸ í‘œì‹œ
if st.session_state.report_done and st.session_state.report_text:
    st.warning("ğŸš¨ ìœ„í—˜ ìƒí™©ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.text_area("í˜„ì¥ ë¦¬í¬íŠ¸(ê°„ê²°, ê³¼ì¥ ê¸ˆì§€)", st.session_state.report_text, height=250)
    cols = st.columns(2)
    if cols[0].button("ë¦¬í¬íŠ¸ ì´ˆê¸°í™”"):
        st.session_state.report_text = ""
        st.session_state.report_done = False
        st.rerun()
    if cols[1].button("ê·¼ì ‘ ì„ê³„ê°’ +20px"):
        globals()["PROXIMITY_PX"] = min(500, PROXIMITY_PX + 20)
        st.toast(f"ì„ê³„ê°’ì„ {PROXIMITY_PX-20} â†’ {PROXIMITY_PX}px ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.")
